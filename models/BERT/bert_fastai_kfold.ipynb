{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1029,
     "status": "ok",
     "timestamp": 1586638932210,
     "user": {
      "displayName": "Vinícios Carvalho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjhp5co0d_AUKLWGcNdVqI7Qn0syOObU223e5VE7Hs=s64",
      "userId": "11287658652742546493"
     },
     "user_tz": 240
    },
    "id": "MEtoHJK4Owb8",
    "outputId": "5df90668-a90c-4564-afe5-85b5d8e47f5f"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "SIZE = \"2k4\"\n",
    "C = \"b\"\n",
    "FOLDER = \"/\" #path to model folder\n",
    "FOLDS_PATH = \"/\" #path where the folds are saved\n",
    "DATA_FOLDER = \"/\" #path where the entire dataset is saved\n",
    "BATCH_SIZE = 32 \n",
    "# LANG = \"BERT-MULTILINGUAL\"\n",
    "# model_name = \"bert-base-multilingual-uncased\"\n",
    "LANG = \"BERT-PORTUGUESE\"\n",
    "model_name = \"neuralmind/bert-base-portuguese-cased\"\n",
    "CLASS_NAME = {2:['Sem Risco', 'Risco Potencial'], 3:['Sem Risco', 'Risco Potencial', 'Risco Alto']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4310,
     "status": "ok",
     "timestamp": 1586638935510,
     "user": {
      "displayName": "Vinícios Carvalho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjhp5co0d_AUKLWGcNdVqI7Qn0syOObU223e5VE7Hs=s64",
      "userId": "11287658652742546493"
     },
     "user_tz": 240
    },
    "id": "AUkwQtGOuIp1",
    "outputId": "de963190-8e49-4a13-d417-f760655c1fae"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJOxdU8Ixqq7"
   },
   "source": [
    "# Carregando o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4296,
     "status": "ok",
     "timestamp": 1586638935512,
     "user": {
      "displayName": "Vinícios Carvalho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjhp5co0d_AUKLWGcNdVqI7Qn0syOObU223e5VE7Hs=s64",
      "userId": "11287658652742546493"
     },
     "user_tz": 240
    },
    "id": "8nhAhfDExp6p",
    "outputId": "ad506be0-2917-475a-86f0-4d456f47a396"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4FyFUZKwx2DM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from time import ctime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tl5yCQrwziVQ"
   },
   "source": [
    "# HuggingFace Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b2uFIotszatf"
   },
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "03zbi81g0CDB"
   },
   "source": [
    "## Integração com FastAi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2uMlboM50Wg4"
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DYBJOT7D0mXR"
   },
   "source": [
    "**Tokenizador:** classe responsável por tokenizar o texto, sendo criada a partir da classe BaseTokenizer do FastAi. Além de tokenizar o texto utilizando um tokenizador já treinado, o mesmo adiciona os tokens especiais CLS e SEP necessários para o BERT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14l43wdXzm-G"
   },
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
    "    def __init__(self, pretrained_tokenizer, seq_len=512, model_type = 'bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = seq_len\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        if self.model_type in ['roberta']:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "        else:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
    "        return [CLS] + tokens + [SEP]\n",
    "        \n",
    "transformer_tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JF7Qmymq1Z21"
   },
   "source": [
    "**Numericalizer:** classe responsável por converter tokens em índices(inteiros) que serão utilizados como entrada para o BERT. A conversão em índices é feita baseando-se em um vocabulário pré-definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHvZFOU11ImS"
   },
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hURp2Yn12pZ"
   },
   "source": [
    "# FastAi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7na5nynm3i17"
   },
   "outputs": [],
   "source": [
    "bs = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMM0HmZU1UFh"
   },
   "outputs": [],
   "source": [
    "transformer_vocab =  TransformersVocab(tokenizer=transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "# False para prevenir a adição de tokens desnecessários pelo processador\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, \n",
    "                                       include_bos=False, \n",
    "                                       include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aitf5LCt164Q"
   },
   "outputs": [],
   "source": [
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ifOlOXVy3qha"
   },
   "source": [
    "# Encapsulando o BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JtM2Uf2V3EON"
   },
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "  \n",
    "    def __init__(self, transformer_model):\n",
    "        super(BERT,self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        # Return only the logits from the transfomer\n",
    "        logits = self.transformer(input_ids)[0]   \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CgTqg1g_Z2i0"
   },
   "source": [
    "#Carregando os folds e realizando o treino em cada um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 976947,
     "status": "ok",
     "timestamp": 1586639908254,
     "user": {
      "displayName": "Vinícios Carvalho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjhp5co0d_AUKLWGcNdVqI7Qn0syOObU223e5VE7Hs=s64",
      "userId": "11287658652742546493"
     },
     "user_tz": 240
    },
    "id": "BeG_DhqB4EGS",
    "outputId": "39b64904-094b-4019-b7d8-e432a020f49b"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "folds = int(len([name for name in os.listdir(FOLDS_PATH) if os.path.isfile(os.path.join(FOLDS_PATH,name))]) / 2)\n",
    "\n",
    "val_acc = []\n",
    "val_prec = []\n",
    "val_rec = []\n",
    "val_f1 = []\n",
    "\n",
    "for f in range(folds):\n",
    "  \n",
    "  print(\"Fold\",f,'\\n')\n",
    "  train_df = pd.read_csv(FOLDS_PATH + \"train\"+str(f) + \".csv\", sep=\"\\t\", index_col=False)\n",
    "  test_df = pd.read_csv(FOLDS_PATH + \"test\"+str(f) + \".csv\", sep=\"\\t\", index_col=False)\n",
    "  CLASSES = len(test_df['y'].unique())\n",
    "\n",
    "  transformer_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=CLASSES)\n",
    "  transformer_model = BERT(transformer_model=transformer_model)\n",
    "  transformer_model = transformer_model.cuda()\n",
    "\n",
    "  \n",
    "  databunch = (TextList.from_df(train_df, cols='text', processor=transformer_processor)\n",
    "             .split_by_rand_pct(0.1,seed=9999)\n",
    "             .label_from_df(cols= 'y')\n",
    "             .add_test(test_df)\n",
    "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))\n",
    "  \n",
    "  learner = Learner(databunch, \n",
    "                  transformer_model, \n",
    "                  opt_func = lambda input: AdamW(input, correct_bias=False), \n",
    "                  metrics=[accuracy, Precision(average=\"macro\"), Recall(average=\"macro\"), FBeta(average=\"macro\", beta=1)])\n",
    "  # learner.lr_find()\n",
    "  # learner.recorder.plot()\n",
    "  learner.fit_one_cycle(5, max_lr=1e-5)\n",
    "\n",
    "  loss_value, acc_value, prec_value, rec_value, f1_value = learner.validate()\n",
    "  val_acc.append(acc_value.item())\n",
    "  val_prec.append(prec_value.item())\n",
    "  val_rec.append(rec_value.item())\n",
    "  val_f1.append(f1_value.item())\n",
    "  learner.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cr3zFA2KVPd3"
   },
   "source": [
    "#Classificador com Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1068007,
     "status": "ok",
     "timestamp": 1586639999336,
     "user": {
      "displayName": "Vinícios Carvalho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjhp5co0d_AUKLWGcNdVqI7Qn0syOObU223e5VE7Hs=s64",
      "userId": "11287658652742546493"
     },
     "user_tz": 240
    },
    "id": "2H7ihMIhVORW",
    "outputId": "200dd3e7-a743-4415-ecb4-4b30280665cc"
   },
   "outputs": [],
   "source": [
    "learner.destroy()\n",
    "train_df = pd.read_csv(DATA_FOLDER + \"ideacao-{}-{}-train.csv\".format(SIZE, C), sep=\"\\t\", index_col=False)\n",
    "test_df = pd.read_csv(DATA_FOLDER + \"ideacao-{}-{}-test.csv\".format(SIZE, C), sep=\"\\t\", index_col=False)\n",
    "\n",
    "CLASSES = len(test_df['y'].unique())\n",
    "\n",
    "transformer_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=CLASSES)\n",
    "transformer_model = BERT(transformer_model=transformer_model)\n",
    "transformer_model = transformer_model.cuda()\n",
    "databunch = (TextList.from_df(train_df, cols='text', processor=transformer_processor)\n",
    "            .split_by_rand_pct(0.1,seed=9999)\n",
    "            .label_from_df(cols= 'y')\n",
    "            .add_test(test_df)\n",
    "            .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))\n",
    "\n",
    "learner = Learner(databunch, \n",
    "                transformer_model, \n",
    "                opt_func = lambda input: AdamW(input, correct_bias=False), \n",
    "                metrics=[accuracy, Precision(average=\"macro\"), Recall(average=\"macro\"), FBeta(average=\"macro\", beta=1)])\n",
    "\n",
    "learner.fit_one_cycle(5, max_lr=1e-5)\n",
    "# learner.lr_find()\n",
    "# learner.recorder.plot()\n",
    "\n",
    "loss, acc, prec, rec, f1 = learner.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j2x71g2aVqd6"
   },
   "source": [
    "#Salvando resultados no arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OamriPhHz0nO"
   },
   "outputs": [],
   "source": [
    "# LANG = \"BERT-MULTILINGUAL\"\n",
    "created_at = ctime()\n",
    "created_at = created_at.replace(' ', '-')\n",
    "name = \"{}-{}-{}-{}-class-results.csv\".format(LANG, SIZE, created_at, CLASSES)\n",
    "with open(os.path.join(FOLDER, 'results', name), 'w') as f:\n",
    "  f.write(\"folds, acc, prec, rec, f1\\n\")\n",
    "  f.write(\"{},{},{},{},{}\\n\".format(folds, np.mean(val_acc), np.mean(val_prec), np.mean(val_rec), np.mean(val_f1)))  \n",
    "  f.write(\"{},{},{},{},{}\\n\".format('-', acc, prec, rec, f1))  \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert_fastai_kfold.ipynb",
   "provenance": [
    {
     "file_id": "11E-J09W51D2fkytK7ZBwJ-CIkNo7a_6L",
     "timestamp": 1585247214114
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
